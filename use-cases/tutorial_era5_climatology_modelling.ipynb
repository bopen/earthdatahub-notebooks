{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ffd2ed95-2962-4e1e-8e2c-1671f0cadb67",
      "metadata": {
        "id": "ffd2ed95-2962-4e1e-8e2c-1671f0cadb67"
      },
      "source": [
        "# How to work with ERA5 single levels on Earth Data Hub\n",
        "### Modelling of climate zones in Europe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d876a60d-c381-431f-8b56-d82d6e68ecca",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-05T16:27:30.942568Z",
          "iopub.status.busy": "2024-01-05T16:27:30.941820Z",
          "iopub.status.idle": "2024-01-05T16:27:30.953114Z",
          "shell.execute_reply": "2024-01-05T16:27:30.950996Z",
          "shell.execute_reply.started": "2024-01-05T16:27:30.942515Z"
        },
        "id": "d876a60d-c381-431f-8b56-d82d6e68ecca"
      },
      "source": [
        "***\n",
        "This notebook will provide you guidance on how to access and use the `ecv-for-climate-change-1979-2023.zarr` datset on Earth Data Hub (EDH).\n",
        "\n",
        "The first goal is to compute monthly averages over Europe.\n",
        "\n",
        "The second goal is model a given number of different climate using a profile classification model.\n",
        "***\n",
        "\n",
        "## What you will learn:\n",
        "\n",
        "* how to access and preview the dataset\n",
        "* select and reduce the data\n",
        "* define a profile classification model (PCM)\n",
        "* plot the results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparation of software packages for Google Colab\n",
        "***\n",
        "\n",
        "* The zarr package is needed by xarray to use engine=\"zarr\" for Earth Data Hub datasets, needs to be installed before xarray is imported\n",
        "* The s3fs package is needed to access S3\n"
      ],
      "metadata": {
        "id": "tEfAa5zFHWkL"
      },
      "id": "tEfAa5zFHWkL"
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "# this cell might need to be run twice to solve version conflicts\n",
        "# can not use the apt package python3-zarr because of too old numcodecs without BitRound compressor\n",
        "#!apt-get remove -y python3-numcodecs\n",
        "\n",
        "!pip install zarr\n",
        "!pip install cartopy\n",
        "# use latest pyxpcm to avoid incompatibility with new numpy versions\n",
        "#!pip install pyxpcm\n",
        "!pip install ipython==8.3.0\n",
        "!pip install git+https://github.com/obidam/pyxpcm.git@master\n"
      ],
      "metadata": {
        "id": "38-d7zkoHcOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "749cc298-5e0b-4c22-da20-5e80a8da9210"
      },
      "id": "38-d7zkoHcOA",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zarr\n",
            "  Downloading zarr-2.17.0-py3-none-any.whl (207 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/207.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/207.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asciitree (from zarr)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from zarr) (1.25.2)\n",
            "Collecting numcodecs>=0.10.0 (from zarr)\n",
            "  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners (from zarr)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5033 sha256=e52de02e04f7c646058930e11cff7510f88f277f7663467006ccdee27bb4ad1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, numcodecs, fasteners, zarr\n",
            "Successfully installed asciitree-0.3.3 fasteners-0.19 numcodecs-0.12.1 zarr-2.17.0\n",
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.4 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.3)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (23.2)\n",
            "Requirement already satisfied: pyshp>=2.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.4->cartopy) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.1.0->cartopy) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->cartopy) (1.16.0)\n",
            "Installing collected packages: cartopy\n",
            "Successfully installed cartopy-0.22.0\n",
            "Collecting git+https://github.com/obidam/pyxpcm.git@master\n",
            "  Cloning https://github.com/obidam/pyxpcm.git (to revision master) to /tmp/pip-req-build-aevqgwbs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/obidam/pyxpcm.git /tmp/pip-req-build-aevqgwbs\n",
            "  Resolved https://github.com/obidam/pyxpcm.git to commit 40b9140d540512db024a2e6945107ccca2122bed\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from pyxpcm==0.4.2.dev50+g40b9140) (1.11.4)\n",
            "Requirement already satisfied: xarray>=2022.3.0 in /usr/local/lib/python3.10/dist-packages (from pyxpcm==0.4.2.dev50+g40b9140) (2023.7.0)\n",
            "Requirement already satisfied: scikit-learn>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from pyxpcm==0.4.2.dev50+g40b9140) (1.2.2)\n",
            "Collecting ipython>=8.3.0 (from pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading ipython-8.22.1-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting netCDF4>=1.5.8 (from pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading netCDF4-1.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dask>=2022.05.0 in /usr/local/lib/python3.10/dist-packages (from pyxpcm==0.4.2.dev50+g40b9140) (2023.8.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from pyxpcm==0.4.2.dev50+g40b9140) (0.12.1)\n",
            "Collecting numpydoc>=0.6.0 (from pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (7.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (4.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (2.16.1)\n",
            "Collecting stack-data (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting traitlets>=5.13.0 (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading traitlets-5.14.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (1.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (4.9.0)\n",
            "Collecting cftime (from netCDF4>=1.5.8->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading cftime-1.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4>=1.5.8->pyxpcm==0.4.2.dev50+g40b9140) (2024.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4>=1.5.8->pyxpcm==0.4.2.dev50+g40b9140) (1.25.2)\n",
            "Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (5.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (3.1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (0.9.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.0.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->pyxpcm==0.4.2.dev50+g40b9140) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.1->pyxpcm==0.4.2.dev50+g40b9140) (3.3.0)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray>=2022.3.0->pyxpcm==0.4.2.dev50+g40b9140) (1.5.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray>=2022.3.0->pyxpcm==0.4.2.dev50+g40b9140) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray>=2022.3.0->pyxpcm==0.4.2.dev50+g40b9140) (2023.4)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask>=2022.05.0->pyxpcm==0.4.2.dev50+g40b9140) (1.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (0.2.13)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.0.7)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.31.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython>=8.3.0->pyxpcm==0.4.2.dev50+g40b9140) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->sphinx>=5->numpydoc>=0.6.0->pyxpcm==0.4.2.dev50+g40b9140) (2.0.7)\n",
            "Building wheels for collected packages: pyxpcm\n",
            "  Building wheel for pyxpcm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxpcm: filename=pyxpcm-0.4.2.dev50+g40b9140-py3-none-any.whl size=51895 sha256=a0fbe766f60839ad5258556f8335d8ea46182c44018f53d25fe11e66762c9e15\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iy1hblsd/wheels/0b/21/ea/1342e4e2ab828b3fc39d6006369a1bd63725d2341c72fbff91\n",
            "Successfully built pyxpcm\n",
            "Installing collected packages: pure-eval, traitlets, jedi, executing, cftime, asttokens, stack-data, netCDF4, numpydoc, ipython, pyxpcm\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: ipython\n",
            "    Found existing installation: ipython 7.34.0\n",
            "    Uninstalling ipython-7.34.0:\n",
            "      Successfully uninstalled ipython-7.34.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asttokens-2.4.1 cftime-1.6.3 executing-2.0.1 ipython-8.22.1 jedi-0.19.1 netCDF4-1.6.5 numpydoc-1.6.0 pure-eval-0.2.2 pyxpcm-0.4.2.dev50+g40b9140 stack-data-0.6.3 traitlets-5.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for S3 filesystem incl. python package"
      ],
      "metadata": {
        "id": "eztHDGAo2ufm"
      },
      "id": "eztHDGAo2ufm"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install s3fs\n",
        "\n",
        "#!pip install fsspec==2023.6.0\n",
        "!pip uninstall -y s3fs\n",
        "#!pip uninstall -y gcsfs\n",
        "#!pip uninstall -y fsspec\n",
        "\n",
        "# the s3fs version must match the already installed version of gcsfs\n",
        "!pip install s3fs==2023.6.0\n"
      ],
      "metadata": {
        "id": "77ZQv00yaiJW"
      },
      "id": "77ZQv00yaiJW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load packages needed for this tutorial"
      ],
      "metadata": {
        "id": "7EZIjuldIGSW"
      },
      "id": "7EZIjuldIGSW"
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "print(\"xarray: %s, %s\" % (xr.__version__, xr.__file__))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyxpcm\n",
        "print(\"pyxpcm: %s, %s\" % (pyxpcm.__version__, pyxpcm.__file__))\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "4cCP-q5LIFHm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "be99342a-76dc-4a75-d105-619e5286926d"
      },
      "id": "4cCP-q5LIFHm",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xarray: 2023.7.0, /usr/local/lib/python3.10/dist-packages/xarray/__init__.py\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pyxpcm'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cfd7ba624991>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyxpcm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyxpcm: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpyxpcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyxpcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyxpcm'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f352e223-34e0-4e20-88c7-40e7a565bf66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-08T18:02:14.626875Z",
          "iopub.status.busy": "2024-01-08T18:02:14.608970Z",
          "iopub.status.idle": "2024-01-08T18:02:14.662440Z",
          "shell.execute_reply": "2024-01-08T18:02:14.644714Z",
          "shell.execute_reply.started": "2024-01-08T18:02:14.626767Z"
        },
        "id": "f352e223-34e0-4e20-88c7-40e7a565bf66"
      },
      "source": [
        "## Data access and preview\n",
        "***\n",
        "\n",
        "Xarray and Dask work together following a lazy principle. This means when you access and manipulate a Zarr store the data is in not immediately downloaded and loaded in memory. Instead, Dask constructs a task graph that represents the operations to be performed. A smart user will reduce the amount of data that needs to be downloaded before the computation takes place (e.g., when the `.compute()` or `.plot()` methods are called).\n",
        "\n",
        "To preview the data, only the dataset metadata must be downloaded. Xarray does this automatically:\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae7e877a-ab49-4280-8fdd-4aa40ca6a3d8",
      "metadata": {
        "id": "ae7e877a-ab49-4280-8fdd-4aa40ca6a3d8"
      },
      "outputs": [],
      "source": [
        "# your `~/.netrc` file MUST contain your credentials for earthdatahub.com\n",
        "#\n",
        "# machine earthdatahub.com\n",
        "#   login {your_username}\n",
        "#   password {your_password}\n",
        "\n",
        "ds = xr.open_dataset(\"s3://hedp/era5/ecv-for-climate-change-1979-2023.zarr\", chunks={}, engine=\"zarr\").astype(\"float32\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ERA5 climate variables from EarthDataHub\n",
        "# url for testing, not official\n",
        "#dataset_url = \"https://user1:lojppbmcw2EMwVRSHv8s0OKR@earthdatahub.com/stores/hedp/era5/ecv-for-climate-change-1979-2023.zarr\"\n",
        "dataset_url = \"https://user1:lojppbmcw2EMwVRSHv8s0OKR@earthdatahub.com/stores/ecmwf-era5-single-levels/reanalysis-era5-single-levels-v0.zarr\"\n",
        "ds = xr.open_dataset(dataset_url, chunks={}, engine=\"zarr\", storage_options={\"client_kwargs\": {\"trust_env\": True}})\n",
        "# .astype(\"float32\")\n",
        "ds"
      ],
      "metadata": {
        "id": "EdvrzyDJIBkd"
      },
      "id": "EdvrzyDJIBkd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "023469bd-f4b1-4761-aaf1-e64490601446",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "023469bd-f4b1-4761-aaf1-e64490601446"
      },
      "source": [
        "## Working with data\n",
        "\n",
        "Datasets on EDH are typically very large and remotely hosted. Typical use imply a selection of the data followed by one or more reduction steps to be performed in a local or distributed Dask environment.\n",
        "\n",
        "The structure of a workflow that uses EDH data looks like this:\n",
        "1. data selection\n",
        "2. (optional) data reduction\n",
        "3. (optional) visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266ba11-3a44-4c5b-be6a-9dcf5867ad07",
      "metadata": {
        "id": "6266ba11-3a44-4c5b-be6a-9dcf5867ad07"
      },
      "source": [
        "## Long-term monthly averages of the variables for Europe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6485a64-5b6f-41e9-a358-d7acb645ab7d",
      "metadata": {
        "id": "c6485a64-5b6f-41e9-a358-d7acb645ab7d"
      },
      "source": [
        "### 1. Data selection\n",
        "\n",
        "We perform a geographical selection corresponding to the central Europe area. This reduces the amount of data that will be downloaded from EDH."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0209ab25-6c99-4cc5-9424-c3e3b4c4de99",
      "metadata": {
        "id": "0209ab25-6c99-4cc5-9424-c3e3b4c4de99"
      },
      "outputs": [],
      "source": [
        "ds_europe = ds.sel(**{\"latitude\": slice(55, 45), \"longitude\": slice(2, 24)})\n",
        "ds_europe"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f3a0c2c-23fc-4cf6-a1a8-5b4cd29045d6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-01-08T12:06:15.865654Z",
          "iopub.status.busy": "2024-01-08T12:06:15.865172Z",
          "iopub.status.idle": "2024-01-08T12:06:15.922646Z",
          "shell.execute_reply": "2024-01-08T12:06:15.913684Z",
          "shell.execute_reply.started": "2024-01-08T12:06:15.865616Z"
        },
        "id": "9f3a0c2c-23fc-4cf6-a1a8-5b4cd29045d6"
      },
      "source": [
        "### 2. Data reduction\n",
        "\n",
        "Now we want monthly long-term averages, but only for the last 30 years (the dataset starts at 1940-01-01):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_europe_30yrs = ds_europe.sel(valid_time=slice(\"1991-01-01\", \"2020-12-31\"))\n",
        "ds_europe_30yrs"
      ],
      "metadata": {
        "id": "iWggDAZCB_Ay"
      },
      "id": "iWggDAZCB_Ay",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Windspeed is an interesting variable to add to the modelling of climate zones, but it takes some time to calculate wind speed from the u and v components which must happen before any spatial or temporal aggregation. Therefore windspeed is disabled by default,but can be enabled by setting `USE_WINDSPEED` to `True`."
      ],
      "metadata": {
        "id": "D3LrgHXDeFjY"
      },
      "id": "D3LrgHXDeFjY"
    },
    {
      "cell_type": "code",
      "source": [
        "USE_WINDSPEED = False\n",
        "\n",
        "if USE_WINDSPEED:\n",
        "  ds_europe_30yrs = ds_europe_30yrs.assign(windspeed=lambda x: np.sqrt(x.u10 * x.u10 + x.v10 * x.v10))\n"
      ],
      "metadata": {
        "id": "m7Kq2EJeeG-4"
      },
      "id": "m7Kq2EJeeG-4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Long-term monthly averages:"
      ],
      "metadata": {
        "id": "yYkKSxEKoJFS"
      },
      "id": "yYkKSxEKoJFS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff1ec496-e06b-4941-b31c-441008eee584",
      "metadata": {
        "id": "ff1ec496-e06b-4941-b31c-441008eee584"
      },
      "outputs": [],
      "source": [
        "ds_europe_lt_monthly = ds_europe_30yrs.groupby(\"valid_time.month\").mean(\"valid_time\")\n",
        "ds_europe_lt_monthly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "At this point, no data has been downloaded yet, nor loaded in memory. However, the selection is small enough to call `.compute()` on it. This will trigger the download of data from EDH and load it in memory.\n",
        "\n",
        "We can measure the time it takes, should be about 8 minutes:\n"
      ],
      "metadata": {
        "id": "1Ja6Am1QKw-n"
      },
      "id": "1Ja6Am1QKw-n"
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "ds_europe_lt_monthly = ds_europe_lt_monthly.compute()"
      ],
      "metadata": {
        "id": "wgsytVzZK0wE"
      },
      "id": "wgsytVzZK0wE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5d1b90cf-17bd-433c-b2aa-d4fdd2c4ab60",
      "metadata": {
        "id": "5d1b90cf-17bd-433c-b2aa-d4fdd2c4ab60"
      },
      "source": [
        "### 3. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "896ef114-b3b0-42db-b308-1e4b745a6fd4",
      "metadata": {
        "id": "896ef114-b3b0-42db-b308-1e4b745a6fd4"
      },
      "source": [
        "We can plot the average precipitation for July on a map:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba8c8148-0bc8-4c15-8b95-f2935a0f1d50",
      "metadata": {
        "scrolled": true,
        "id": "ba8c8148-0bc8-4c15-8b95-f2935a0f1d50"
      },
      "outputs": [],
      "source": [
        "from cartopy import crs, feature\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ds_europe_lt_monthly_dec = ds_europe_lt_monthly.sel(month=7)\n",
        "dec_tp = ds_europe_lt_monthly_dec.tp\n",
        "\n",
        "_, ax = plt.subplots(\n",
        "    figsize=(6, 6),\n",
        "    subplot_kw={\"projection\": crs.Miller()},\n",
        ")\n",
        "dec_tp.plot(\n",
        "    ax=ax,\n",
        "    cmap=\"YlOrRd\",\n",
        "    transform=crs.PlateCarree(),\n",
        "    cbar_kwargs={\"orientation\": \"horizontal\", \"pad\": 0.05, \"aspect\": 40, \"label\": \"Average precipitation for July [m]\"},\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.add_feature(feature.BORDERS)\n",
        "ax.set_title(\"Average July precipitation\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a56c1a8-4f6f-47b1-9417-47452d27955a",
      "metadata": {
        "id": "4a56c1a8-4f6f-47b1-9417-47452d27955a"
      },
      "source": [
        "## Profile Classification Model (PCM)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d37b18-ac56-455e-89a1-4a4c8e67bb36",
      "metadata": {
        "id": "64d37b18-ac56-455e-89a1-4a4c8e67bb36"
      },
      "source": [
        "We want to determine homogeneous climatic zones in Europe using the monthly long-term averages."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a model"
      ],
      "metadata": {
        "id": "yHhgqOOhyRH0"
      },
      "id": "yHhgqOOhyRH0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import the Profile Classification Model (PCM) constructor:"
      ],
      "metadata": {
        "id": "1it4DqcSyY01"
      },
      "id": "1it4DqcSyY01"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cec8215-c12f-498d-8eb3-2d1aef0ae7b0",
      "metadata": {
        "scrolled": true,
        "id": "7cec8215-c12f-498d-8eb3-2d1aef0ae7b0"
      },
      "outputs": [],
      "source": [
        "from pyxpcm.models import pcm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A PCM can be created independently of any dataset using the class constructor.\n",
        "\n",
        "A PCM requires a number of classes (or clusters) and a dictionary to define the list of features and their profile axis:"
      ],
      "metadata": {
        "id": "_62xkY7IymWE"
      },
      "id": "_62xkY7IymWE"
    },
    {
      "cell_type": "code",
      "source": [
        "z = np.arange(-1, -12, -1)\n",
        "if USE_WINDSPEED:\n",
        "  pcm_features = {'temperature': z, 'precipitation':z, 'windspeed': z}\n",
        "else:\n",
        "  pcm_features = {'temperature': z, 'precipitation':z}"
      ],
      "metadata": {
        "id": "mVHhZJdvyrWa"
      },
      "id": "mVHhZJdvyrWa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now instantiate a PCM, say with 8 classes:"
      ],
      "metadata": {
        "id": "uCE144leHONi"
      },
      "id": "uCE144leHONi"
    },
    {
      "cell_type": "code",
      "source": [
        "# error in PCA:\n",
        "# ValueError: n_components=15 must be between 0 and min(n_samples, n_features)=11 with svd_solver='full'\n",
        "# n_components is set somewhere internally\n",
        "# -> try without PCA: reduction=0\n",
        "\n",
        "m = pcm(K=8, features=pcm_features, reduction=0)\n",
        "m"
      ],
      "metadata": {
        "id": "pWXdqjTOHQN9"
      },
      "id": "pWXdqjTOHQN9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit the model on data"
      ],
      "metadata": {
        "id": "y6p5w0cLHj5O"
      },
      "id": "y6p5w0cLHj5O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting can be done on any dataset coherent with the PCM definition, in a sense that it must have the feature variables of the PCM.\n",
        "\n",
        "To tell the PCM model how to identify features in any :class:`xarray.Dataset`, we need to provide a dictionary of variable names mapping:"
      ],
      "metadata": {
        "id": "yJjIJMY0H2E_"
      },
      "id": "yJjIJMY0H2E_"
    },
    {
      "cell_type": "code",
      "source": [
        "if USE_WINDSPEED:\n",
        "  features_in_ds = {'temperature': 't2m', 'precipitation': 'tp', 'windspeed': 'windspeed'}\n",
        "else:\n",
        "  features_in_ds = {'temperature': 't2m', 'precipitation': 'tp'}\n"
      ],
      "metadata": {
        "id": "DUo-s4raH3xR"
      },
      "id": "DUo-s4raH3xR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "which means that the PCM feature ``temperature`` is to be found in the dataset variables ``t2m``.\n",
        "\n",
        "We also need to specify the profile dimension of the dataset variables:"
      ],
      "metadata": {
        "id": "btqp-JwFJxZi"
      },
      "id": "btqp-JwFJxZi"
    },
    {
      "cell_type": "code",
      "source": [
        "features_pdim='month'"
      ],
      "metadata": {
        "id": "a0iYt1g0J46P"
      },
      "id": "a0iYt1g0J46P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values of the profile dimension must be <= 0:"
      ],
      "metadata": {
        "id": "GVjc0uEGyS7n"
      },
      "id": "GVjc0uEGyS7n"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_europe_lt_monthly_neg = ds_europe_lt_monthly.assign_coords(month=(-ds_europe_lt_monthly.month))"
      ],
      "metadata": {
        "id": "szD4RlSYyaBg"
      },
      "id": "szD4RlSYyaBg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_europe_lt_monthly_neg = ds_europe_lt_monthly_neg.compute()\n",
        "ds_europe_lt_monthly_neg"
      ],
      "metadata": {
        "id": "pG8IhmnyzMq9"
      },
      "id": "pG8IhmnyzMq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we're ready to fit the model on the this dataset:"
      ],
      "metadata": {
        "id": "akqxAvqwJ-xM"
      },
      "id": "akqxAvqwJ-xM"
    },
    {
      "cell_type": "code",
      "source": [
        "m.fit(ds_europe_lt_monthly_neg, features=features_in_ds, dim=features_pdim)\n",
        "m"
      ],
      "metadata": {
        "id": "YDkhmslRJ_iv"
      },
      "id": "YDkhmslRJ_iv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify data"
      ],
      "metadata": {
        "id": "Xn4FHeMJKV4S"
      },
      "id": "Xn4FHeMJKV4S"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the PCM is fitted, we can predict the classification results like:"
      ],
      "metadata": {
        "id": "DKk26M5_KbEV"
      },
      "id": "DKk26M5_KbEV"
    },
    {
      "cell_type": "code",
      "source": [
        "m.predict(ds_europe_lt_monthly_neg, features=features_in_ds, dim=features_pdim, inplace=True)\n",
        "ds_europe_lt_monthly_neg"
      ],
      "metadata": {
        "id": "GmPHTIHhKcC8"
      },
      "id": "GmPHTIHhKcC8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction labels are automatically added to the dataset as `PCM_LABELS` because the option `inplace` was set to `True`."
      ],
      "metadata": {
        "id": "etfCp90TK-n4"
      },
      "id": "etfCp90TK-n4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "pyXpcm use a Gaussian Mixture Model (GMM) classifier by default, which is a fuzzy classifier. So we can also predict the probability of each classes for all profiles, the so-called *posteriors*:"
      ],
      "metadata": {
        "id": "eUjB4RR2LJmt"
      },
      "id": "eUjB4RR2LJmt"
    },
    {
      "cell_type": "code",
      "source": [
        "m.predict_proba(ds_europe_lt_monthly_neg, features=features_in_ds, dim=features_pdim, inplace=True)\n",
        "ds_europe_lt_monthly_neg"
      ],
      "metadata": {
        "id": "SSNo5VLcLPMK"
      },
      "id": "SSNo5VLcLPMK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "which are added to the dataset as the `PCM_POST` variables. The probability of classes for each profiles has a new dimension `pcm_class` by default that goes from 0 to K-1."
      ],
      "metadata": {
        "id": "7p1iUugmLcKT"
      },
      "id": "7p1iUugmLcKT"
    },
    {
      "cell_type": "code",
      "source": [
        "classno = 2\n",
        "ds_plt = ds_europe_lt_monthly_neg['PCM_POST'].sel(pcm_class=classno)\n"
      ],
      "metadata": {
        "id": "yXhdkOTDpccF"
      },
      "id": "yXhdkOTDpccF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Geographic distribution of classes"
      ],
      "metadata": {
        "id": "i1Ie9zRWUxGV"
      },
      "id": "i1Ie9zRWUxGV"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_plt = ds_europe_lt_monthly_neg['PCM_LABELS']\n",
        "\n",
        "_, ax = plt.subplots(\n",
        "    figsize=(6, 6),\n",
        "    subplot_kw={\"projection\": crs.Miller()},\n",
        ")\n",
        "ds_plt.plot(\n",
        "    ax=ax,\n",
        "    cmap=\"tab20\",\n",
        "    transform=crs.PlateCarree(),\n",
        "    cbar_kwargs={\"orientation\": \"horizontal\", \"pad\": 0.05, \"aspect\": 40, \"label\": \"PCM class numbers\"},\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.add_feature(feature.BORDERS)\n",
        "ax.set_title(\"PCM classes\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BpAelxcnGBEs"
      },
      "id": "BpAelxcnGBEs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show probabilities for a selected class:"
      ],
      "metadata": {
        "id": "-QPfMyb-pztF"
      },
      "id": "-QPfMyb-pztF"
    },
    {
      "cell_type": "code",
      "source": [
        "classno = 2\n",
        "ds_plt = ds_europe_lt_monthly_neg['PCM_POST'].sel(pcm_class=classno)\n",
        "\n",
        "cmap = sns.light_palette(\"blue\", as_cmap=True)\n",
        "\n",
        "_, ax = plt.subplots(\n",
        "    figsize=(6, 6),\n",
        "    subplot_kw={\"projection\": crs.Miller()},\n",
        ")\n",
        "ds_plt.plot(\n",
        "    ax=ax,\n",
        "    cmap=cmap,\n",
        "    transform=crs.PlateCarree(),\n",
        "    cbar_kwargs={\"orientation\": \"horizontal\", \"pad\": 0.05, \"aspect\": 40, \"label\": f\"Probabilities for class no {classno}\"},\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.add_feature(feature.BORDERS)\n",
        "ax.set_title(f\"PCM Probabilities for class no {classno}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ElrFm6OBp054"
      },
      "id": "ElrFm6OBp054",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "MIDaRHnp5OFX"
      },
      "id": "MIDaRHnp5OFX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that once the PCM is fitted, you can predict labels for any dataset, as long as it has the PCM features.\n",
        "\n",
        "For instance, let's predict labels for a single year:"
      ],
      "metadata": {
        "id": "WYGSYfN2L_fG"
      },
      "id": "WYGSYfN2L_fG"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_europe_2023 = ds_europe.sel(valid_time=slice(\"2023-01-01\", \"2023-12-31\"))\n",
        "if USE_WINDSPEED:\n",
        "  ds_europe_2023 = ds_europe_2023.assign(windspeed=lambda x: np.sqrt(x.u10 * x.u10 + x.v10 * x.v10))\n"
      ],
      "metadata": {
        "id": "teQnnOBbMQux"
      },
      "id": "teQnnOBbMQux",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aggregate to monthly data and prepare for PCM"
      ],
      "metadata": {
        "id": "QKCO25GJPQTf"
      },
      "id": "QKCO25GJPQTf"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_europe_2023_monthly = ds_europe_2023.groupby(\"valid_time.month\").mean(\"valid_time\")\n",
        "ds_europe_2023_monthly_neg = ds_europe_2023_monthly.assign_coords(month=(-ds_europe_2023_monthly.month))\n",
        "ds_europe_2023_monthly_neg = ds_europe_2023_monthly_neg.compute()\n",
        "ds_europe_2023_monthly_neg"
      ],
      "metadata": {
        "id": "VtYhJFxnPTGN"
      },
      "id": "VtYhJFxnPTGN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the model"
      ],
      "metadata": {
        "id": "musTUgd4PmtE"
      },
      "id": "musTUgd4PmtE"
    },
    {
      "cell_type": "code",
      "source": [
        "m.predict(ds_europe_2023_monthly_neg, features=features_in_ds, dim=features_pdim, inplace=True)\n",
        "ds_europe_2023_monthly_neg"
      ],
      "metadata": {
        "id": "SKcutin1Po7t"
      },
      "id": "SKcutin1Po7t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show the result"
      ],
      "metadata": {
        "id": "mV9XwRzS5g_8"
      },
      "id": "mV9XwRzS5g_8"
    },
    {
      "cell_type": "code",
      "source": [
        "ds_plt = ds_europe_2023_monthly_neg['PCM_LABELS']\n",
        "\n",
        "_, ax = plt.subplots(\n",
        "    figsize=(6, 6),\n",
        "    subplot_kw={\"projection\": crs.Miller()},\n",
        ")\n",
        "ds_plt.plot(\n",
        "    ax=ax,\n",
        "    cmap=\"tab20\",\n",
        "    transform=crs.PlateCarree(),\n",
        "    cbar_kwargs={\"orientation\": \"horizontal\", \"pad\": 0.05, \"aspect\": 40, \"label\": \"PCM class numbers\"},\n",
        ")\n",
        "ax.coastlines()\n",
        "ax.add_feature(feature.BORDERS)\n",
        "ax.set_title(\"PCM classes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "criDLFM95i7J"
      },
      "id": "criDLFM95i7J",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}